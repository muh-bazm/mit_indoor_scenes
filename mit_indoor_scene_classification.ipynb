{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721ac47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 13:30:03.958616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-21 13:30:04.496085: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-21 13:30:06.437411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-01-21 13:30:06.437537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
      "2023-01-21 13:30:06.437545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71fd4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count_ = 901 \n",
    "batch_size_ = 8\n",
    "\n",
    "img_height_ = 256\n",
    "img_width_ = 256\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e322ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0a4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a6cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir_2 = \"drive/MyDrive/projects/mit_indoor_scence_recognition/datasets/Images/*/*\"\n",
    "dataset_address = \"/home/ubuntu/projects/mit_indoor_scene/data/data_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e52b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 901 files belonging to 5 classes.\n",
      "Using 721 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 17:08:40.674499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:40.683727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:40.685844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:40.688507: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-14 17:08:40.688948: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:40.691054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:40.693032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:41.484149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:41.485141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:41.485926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-14 17:08:41.486655: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-01-14 17:08:41.486774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13641 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "training_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_address,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size= batch_size_,\n",
    "    image_size=(img_height_, img_width_),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9e9780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 901 files belonging to 5 classes.\n",
      "Using 180 files for validation.\n"
     ]
    }
   ],
   "source": [
    "validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_address,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size_,\n",
    "    image_size=(img_height_, img_width_),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdf082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = training_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4098381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_acc(y_true, y_pred):\n",
    "      \n",
    "    Y_true = []\n",
    "    Y_pred = []\n",
    "\n",
    "    for i in range(y_true.shape[0]):\n",
    "        i_ = np.argmax(y_true[i,:])\n",
    "        j_ = np.argmax(y_pred[i,:])\n",
    "        Y_true.append(i_+1)\n",
    "        Y_pred.append(j_+1)\n",
    "    \n",
    "    \n",
    "    return balanced_accuracy_score(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ead9667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 5\n",
    "\n",
    "\n",
    "aug_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  # tf.keras.layers.RandomHeight(0.2, interpolation='bilinear'),\n",
    "  tf.keras.layers.RandomTranslation(0.2, 0.2, fill_mode='reflect', interpolation='bilinear', fill_value=0.0),\n",
    "  # tf.keras.layers.RandomWidth(0.2, interpolation='bilinear'),\n",
    "  tf.keras.layers.RandomZoom(0.2, 0.2, fill_mode='reflect', interpolation='bilinear')  \n",
    "  # tf.keras.layers.Flatten()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c36cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "\n",
    "def get_model(input_layer_):\n",
    "\n",
    "  augmented_input = aug_model(input_layer_)\n",
    "#   conv_1 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu', input_shape=(256, 256, 3))(augmented_input)\n",
    "#   conv_1 = tf.keras.layers.MaxPooling2D()(conv_1)\n",
    "\n",
    "  conv_2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu', input_shape=(256, 256, 3))(augmented_input)\n",
    "  conv_2 = tf.keras.layers.MaxPooling2D()(conv_2)\n",
    "\n",
    "  conv_3 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', input_shape=(256, 256, 3))(conv_2)\n",
    "  conv_3 = tf.keras.layers.MaxPooling2D()(conv_3)\n",
    "\n",
    "  conv_4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', input_shape=(256, 256, 3))(conv_3)\n",
    "  conv_4 = tf.keras.layers.MaxPooling2D()(conv_4)\n",
    "\n",
    "  conv_5 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(conv_4)\n",
    "  conv_5 = tf.keras.layers.MaxPooling2D()(conv_5)\n",
    "\n",
    "  conv_5 = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu')(conv_5)\n",
    "  conv_5 = tf.keras.layers.MaxPooling2D()(conv_5)\n",
    "\n",
    "  flatten = tf.keras.layers.Flatten()(conv_5)\n",
    "#   dense_1 = tf.keras.layers.Dense(256, activation='relu')(flatten)\n",
    "  dense_2 = tf.keras.layers.Dense(128, activation='relu')(flatten)\n",
    "  dense_3 = tf.keras.layers.Dense(32, activation='relu')(dense_2)\n",
    "  dense_4 = tf.keras.layers.Dense(1, activation='softmax')(dense_3)\n",
    "\n",
    "  return dense_4\n",
    "\n",
    "\n",
    "last_layers = list()\n",
    "\n",
    "classes_num = 5\n",
    "\n",
    "for _ in range(classes_num):\n",
    "  last_layer = get_model(input_layer)\n",
    "  last_layers.append(last_layer)\n",
    "\n",
    "\n",
    "output_layer = tf.keras.layers.Concatenate()([ layer_ for layer_ in last_layers ])\n",
    "\n",
    "final_model = tf.keras.Model(input_layer, output_layer, name=\"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ed8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "  metrics=[b_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-14 17:09:21.384094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 1093s 12s/step - loss: 1.6094 - b_acc: 0.1740 - val_loss: 1.6094 - val_b_acc: 0.2036\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 1095s 12s/step - loss: 1.6094 - b_acc: 0.1740 - val_loss: 1.6094 - val_b_acc: 0.2036\n",
      "Epoch 3/10\n",
      "65/91 [====================>.........] - ETA: 5:12 - loss: 1.6094 - b_acc: 0.1923"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(\n",
    "              train_ds,\n",
    "              validation_data=val_ds,\n",
    "              epochs=10,\n",
    "              verbose=1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775496ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
